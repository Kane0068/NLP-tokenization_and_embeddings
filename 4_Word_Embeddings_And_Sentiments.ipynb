{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu76fyrOs2Evg/324xgFTS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WORD EMBEDDİNGS AND SENTİMENTS"
      ],
      "metadata": {
        "id": "Xu5fblWYXY_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Kelime Gömme Yapılacak\n",
        "* Duygu Tahmini için sinir ağı eğitilecek\n",
        "* Her duygunun nasıl göründüğünü görselleştirilecek"
      ],
      "metadata": {
        "id": "_LSxaGKyXtUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1-İmporting Tensorflow libraries"
      ],
      "metadata": {
        "id": "F7ytPCrZXtVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "iAoTheg4XtWT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# İmporting numpy and pandas libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NrhXHRv8ZM6T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Get The Dataset\n",
        "  * Amazon ve Yelp den duyguları içeren bir veri seti içeri aktaracaz\n",
        "  * 1 olumlu 0 olumsuz duyguyu ifade eder"
      ],
      "metadata": {
        "id": "OvtisOfmXtZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    -O /tmp/sentiment.csv https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfgo5cSLXtai",
        "outputId": "33e4357c-f519-4c6b-cf49-51f60b52f0fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-07 00:06:43--  https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.197.102, 173.194.197.101, 173.194.197.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.197.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i62aob8psvimte3dnaj7le0c0crb5487/1678147575000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=87c9480e-1bd7-4945-84b4-170079f84891 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-07 00:06:43--  https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i62aob8psvimte3dnaj7le0c0crb5487/1678147575000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=87c9480e-1bd7-4945-84b4-170079f84891\n",
            "Resolving doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)... 74.125.69.132, 2607:f8b0:4001:c08::84\n",
            "Connecting to doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)|74.125.69.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 127831 (125K) [text/csv]\n",
            "Saving to: ‘/tmp/sentiment.csv’\n",
            "\n",
            "/tmp/sentiment.csv  100%[===================>] 124.83K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-03-07 00:06:43 (129 MB/s) - ‘/tmp/sentiment.csv’ saved [127831/127831]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/tmp/sentiment.csv\")"
      ],
      "metadata": {
        "id": "pwYkXPP7XtbV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AYIKLAMA İŞLEMİ\n",
        "# Cümleleri içeren bir liste seti oluşturalım\n",
        "sentences = dataset['text'].tolist()\n",
        "\n",
        "# Duyguları içeren bir liste oluşturalım\n",
        "labels = dataset['sentiment'].tolist()\n",
        "\n",
        "print(sentences[0:5])\n",
        "print(\"*\"*40)\n",
        "print(labels[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z96ozSDWXtfC",
        "outputId": "7095ffae-b63a-437b-f5df-8e2fc321c2cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['So there is no way for me to plug it in here in the US unless I go by a converter.', 'Good case Excellent value.', 'Great for the jawbone.', 'Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!', 'The mic is great.']\n",
            "****************************************\n",
            "[0, 1, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3-Let's Create Training And Test Sets"
      ],
      "metadata": {
        "id": "BmRqxbczXtf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Öncelikle train ve test setimizin kesilme uzunluğunu belirleyelim\n",
        "# train set 0.8      test set = 0.2 yapalım\n",
        "training_size = int(len(sentences)*0.8)\n",
        "\n",
        "# training size a göre cümleleri ve duyguları train_test setlerimizi oluşturalım\n",
        "training_sentences = sentences[:training_size]\n",
        "testing_sentences = sentences[training_size :]\n",
        "\n",
        "training_labels = labels[:training_size]\n",
        "testing_labels = labels[training_size :]\n",
        "\n",
        "# Etiketleri ağda sonra kullanmak üzere numpy dizisi oluşturalım\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "lS11yOMqXtgn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-Tokenize-Padding Train And Test DataSet"
      ],
      "metadata": {
        "id": "gLl23BphhEUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import truncate\n",
        "#PARAMETRELER\n",
        "vocab_size = 1000   # kelimelere verilecek sayıların boyutu\n",
        "embedding_dim = 16   # gömme boyutu(Bir kelimenin temsil edebileceği boyut)\n",
        "max_length = 100      # cümlelerin max uzunluğu (100 den fazla olan kesilecek)\n",
        "trunc_type = 'post'   # Kesilecek cümle sondan kesilsin(Belirtmezsek varsayılan baştan keser)\n",
        "padding_type = 'post'  # 100 kelimeden küçük olan kelimelerin doldururken arkasına ekle demek istiyoruz\n",
        "oov_tok = \"<OOV>\"   # Tanımadğı kelimeleri temsil etmesi için sabir bir belirteç oluşturuyoruz\n",
        "\n",
        "# tokenizer instance oluşturmakla başlayalım\n",
        "tokenizer = Tokenizer(num_words =vocab_size,oov_token = oov_tok)\n",
        "\n",
        "# kelimeleri diziye çevirelim\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "# Oluşturduğumuz diziyi sözlük halinde alalım\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# *****************************************************\n",
        "\n",
        "#Cümlelerimizi diziye çevirelim\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "\n",
        "# Dizimizi kesme ve padding kullanarak birbirlerine denkleyelim\n",
        "padded = pad_sequences(sequences,maxlen = max_length,padding = padding_type , truncating=trunc_type)\n",
        "\n",
        "\n",
        "# **********************************************************\n",
        "# Test Cümlelerini diziye çevirelim\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "\n",
        "# Denkleme işlemini yapalım kesme padding uzunluk işlemleri\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen = max_length,padding = padding_type,truncating=trunc_type)\n"
      ],
      "metadata": {
        "id": "w2bF5EqFXtj8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5-Review a Sequences"
      ],
      "metadata": {
        "id": "lxpaLFLyXtkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Herşeyin uygun olup olmadığını kontrol edelim\n",
        "\n",
        "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i,'?') for i in text])\n",
        "\n",
        "print(decode_review(padded[1]))\n",
        "print(decode_review(training_sentences[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lieFKE_RXtlh",
        "outputId": "884315bc-548e-4e52-f48a-9dd23779c31d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good case excellent value ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6-Train a Basic Sentiment Model with Embeddings"
      ],
      "metadata": {
        "id": "vSornzGmiTk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelimizi eğitme işlemi için;\n",
        "# Bir ağ oluşturacaz\n",
        "# İlk Katman Gömme katmanı\n",
        "# Çıkış katmanı 0 yada 1 olacağından Tek çıkış olacak\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size , embedding_dim,input_length=max_length), # Gömme işlemi için kelimelerin boyutu,gömme boyutu ve girişte cümlelerin max uzunluğu\n",
        "    tf.keras.layers.Flatten(),  # Düzleştirme işlemi yapıyoruz\n",
        "    tf.keras.layers.Dense(6,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(loss = \"binary_crossentropy\",optimizer = \"adam\",metrics = [\"accuracy\"])  # binary_crossentropy(0-1 için)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR66gLoIiTnk",
        "outputId": "5cc3eaa4-1f8f-4373-9507-7337fade9052"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           16000     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 9606      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,613\n",
            "Trainable params: 25,613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model.fit(padded,training_labels_final,epochs = num_epochs,validation_data = (testing_padded,testing_labels_final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjrh4gr7iTqL",
        "outputId": "23f05251-1b7c-4d61-bd25-1f4a3cd0be1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 11s 115ms/step - loss: 0.6938 - accuracy: 0.5229 - val_loss: 0.6964 - val_accuracy: 0.4110\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.6872 - accuracy: 0.5229 - val_loss: 0.7005 - val_accuracy: 0.4110\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.6739 - accuracy: 0.5229 - val_loss: 0.6976 - val_accuracy: 0.4110\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 1s 29ms/step - loss: 0.6417 - accuracy: 0.6265 - val_loss: 0.6874 - val_accuracy: 0.4687\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 1s 21ms/step - loss: 0.5856 - accuracy: 0.6836 - val_loss: 0.6554 - val_accuracy: 0.6165\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 1s 15ms/step - loss: 0.5210 - accuracy: 0.8060 - val_loss: 0.6588 - val_accuracy: 0.5614\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.4638 - accuracy: 0.8544 - val_loss: 0.6380 - val_accuracy: 0.6140\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.4113 - accuracy: 0.9096 - val_loss: 0.6264 - val_accuracy: 0.6667\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 0.3681 - accuracy: 0.9328 - val_loss: 0.6424 - val_accuracy: 0.6341\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.3292 - accuracy: 0.9592 - val_loss: 0.5415 - val_accuracy: 0.7368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5fc03e5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7-Get files for visualizing the network\n",
        "* Bu işlemi oluşturmuş olduğumuz dizileri görselleştirmek için kullanacağız\n",
        "* İşlem sonunda tsv uzantılı bir dosya elde edeceğiz\n",
        "* Elde ettiğimiz bu dosyayı aşağıdaki adreste load butonunu kullanarak görselleştirme işlemi yapacaz\n",
        "* http://projector.tensorflow.org/"
      ],
      "metadata": {
        "id": "bpoCQKNAiTsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Önce gömme katmanının ağırlıklarını alalım\n",
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape)  # shape : (vocab_size , embeddings_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDRW_yyqiTu4",
        "outputId": "493a5836-6733-4b47-d9a3-315a57c38025"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gömülü vektörleri ve meta verileri yazalım\n",
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "in1P-AOLiTw6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EkciyGQUm1tI",
        "outputId": "f9ca48d0-e6d6-44d9-86df-faf7b33d7111"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af77713d-f725-4a58-9091-51427e7fce56\", \"vecs.tsv\", 191235)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed205560-29a3-492c-979c-aeed78358d7c\", \"meta.tsv\", 6617)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8- Predicting Sentiment in New Reviews\n",
        "* Hiç Görmediği cümlelerin duygularını tahmin edelim\n"
      ],
      "metadata": {
        "id": "T5dcPTdKnpxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cümlelerimizi tanımlayalım\n",
        "fake_reviews = ['I love this phone', 'I hate spaghetti', \n",
        "                'Everything was cold',\n",
        "                'Everything was hot exactly as I wanted', \n",
        "                'Everything was green', \n",
        "                'the host seated us immediately',\n",
        "                'they gave us free chocolate cake', \n",
        "                'not sure about the wilted flowers on the table',\n",
        "                'only works when I stand on tippy toes', \n",
        "                'does not work when I stand on my head']\n",
        "\n",
        "print(fake_reviews) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "868JPShJnp1e",
        "outputId": "5cad8953-8952-4d87-f4b4-e7b2dead0e35"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I love this phone', 'I hate spaghetti', 'Everything was cold', 'Everything was hot exactly as I wanted', 'Everything was green', 'the host seated us immediately', 'they gave us free chocolate cake', 'not sure about the wilted flowers on the table', 'only works when I stand on tippy toes', 'does not work when I stand on my head']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Diziye çevirme işlemi yapalım\n",
        "padding_type = 'post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(fake_reviews)\n",
        "\n",
        "# padding - truncate ve max length işlemlerini yapalım\n",
        "sample_padded = pad_sequences(sample_sequences,padding=padding_type,maxlen = max_length)\n",
        "\n",
        "# Tahmine başlayalım \n",
        "classes = model.predict(sample_padded)\n",
        "\n",
        "# Sonuçlar için bir for döngüsü oluşturalım \n",
        "# 1 e ne kadar yakınsa olumlu olma ihtimali o kadar yüksektir\n",
        "for x in range(len(fake_reviews)):\n",
        "  print(fake_reviews[x])\n",
        "  print(classes[x])\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE7hQORloCkB",
        "outputId": "7201e4ba-63a9-4300-d3e4-98ef7a317140"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "I love this phone\n",
            "[0.9655568]\n",
            "\n",
            "\n",
            "I hate spaghetti\n",
            "[0.27540037]\n",
            "\n",
            "\n",
            "Everything was cold\n",
            "[0.5053474]\n",
            "\n",
            "\n",
            "Everything was hot exactly as I wanted\n",
            "[0.64136773]\n",
            "\n",
            "\n",
            "Everything was green\n",
            "[0.51515454]\n",
            "\n",
            "\n",
            "the host seated us immediately\n",
            "[0.73586786]\n",
            "\n",
            "\n",
            "they gave us free chocolate cake\n",
            "[0.80141467]\n",
            "\n",
            "\n",
            "not sure about the wilted flowers on the table\n",
            "[0.2647199]\n",
            "\n",
            "\n",
            "only works when I stand on tippy toes\n",
            "[0.9228611]\n",
            "\n",
            "\n",
            "does not work when I stand on my head\n",
            "[0.2654422]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}